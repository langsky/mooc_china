HDFS 是Hadoop dfs的简写。

兼容廉价的硬件设备。
实现流数据的读写。 这一点和传统数据系统有区别。
支持大数据集。
支持简单的文件模型。（只允许增加，不允许更改？）

不适合低延迟的访问。（不满足实时读取。HBase满足）
无法高效存储大量小文件。
不支持多用户写入，只允许增加，不允许更改。

## 块

默认64M。支持面向大规模数据存储。减低寻址开销。大小和MapReduce相关联。

## namenode datanode

一个主节点，多个从节点，主节点就是namenode。namenode就相当于是整个HDFS的大管家。
数据结点就是从节点，用来存储数据的节点。

然后了解一下元数据。元数据用来标注数据的属性。

## 名称节点

FsImage 是保存系统文件树，存储元数据用的和访问权限。FsImage不保存数据的实际保存位置。元数据都要保存在内存中。

Editlog 用来记录数据的操作历史。

启动HDFS时，先加载FsImage和EditLog，然后生成一个新的FsImage和空的EditLog，删除旧的内容。

第二名称节点 1. 对EditLog处理，当EditLog不断增大时，2. 冷备份。

## 数据节点

比较简单，不做介绍。

## HDFS体系结构

主从结构。

TCP/IP 通信协议，和名称结点交互

RPC 和数据节点远程操作

1.0版本的局限：

1. 命名空间的限制，名称结点是保存在内存中的，内存是有上限的。
2. 性能由瓶颈，受限于单个名称节点的吞吐量。
3. 只有一个名称结点和命名空间，无法对不同程序进行隔离。
4. 名称节点一旦崩掉，系统就不可用。（第二名称节点是冷备份，不是热备份）

## HDFS存储原理

数据冗余保存：一个数据块，默认保存三份。

1. 加快数据传输速度。
2. 很容易检查数据错误。
3. 保证数据的可靠性。

数据存储原理

1. 副本1放在请求写入的datanode
2. 副本2放在和副本一不同的机架的datanode
3. 其它副本随机写入。

数据错误恢复

1. 名称节点出错怎么办？使用冷备份恢复。或者2.0上直接热备份恢复。
2. 数据节点出错怎么办？数据节点会周期向名称结点发送探测信息，数据节点宕机后，名称节点开始备份数据块。
3. 数据本身出错怎么办？客户端使用校验码来验证数据的正确性，校验码错误，就进行冗余恢复。

## HDFS读的过程



## HDFS写的过程
